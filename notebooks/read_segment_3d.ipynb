{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9e266cd-aea1-48cd-9e76-ef9ccbdbbb45",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pre-process and write to npz for GNN training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89486a71-24e9-4545-9df6-b61188d58a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "re_int_sci = r'[-\\d\\.]+e?[-+\\d]*'\n",
    "re_sci = r'[+-]?\\d+\\.\\d+e[+-]?[\\d]+'\n",
    "\n",
    "## Concrete-2D-CI particle types based on particle index\n",
    "PID_TO_TYPE = {1:   0,   # Seg1\n",
    "               2:   0,   # Seg2\n",
    "               3:   0,   # Seg3\n",
    "               101: 1,   # Anchor_plate1\n",
    "               102: 1,   # Anchor_plate2\n",
    "               103: 1,   # Anchor\n",
    "               104: 2,   # Tendon\n",
    "               201: 3,   # Hammer\n",
    "               211: 3,   # Roller\n",
    "               221: 3,   # Plate_top\n",
    "               222: 3,   # Plate_bot\n",
    "               301: 4,   # Rebar_seg1\n",
    "               302: 4,   # Rebar_seg2\n",
    "               303: 4,   # Rebar_seg3\n",
    "               401: 4,   # Stirrup_seg1\n",
    "               402: 4,   # Stirrup_seg2\n",
    "               403: 4,   # Stirrup_seg3\n",
    "              }\n",
    "\n",
    "def parse_segment_simulation(file):\n",
    "\n",
    "    '''\n",
    "    Extract info from LSDYNA txt.\n",
    "\n",
    "    Input: text file, extracted with the following steps:\n",
    "    1. Load d3plot file\n",
    "    2. Output the 'Element' (eid, pid)\n",
    "    3. Output 'Element Centroid, Volume' by appending all steps (pos)\n",
    "    4. Select \"effective plastic strain\" and unselect all beam parts\n",
    "    5. Output 'Element results' amd append all (eps)\n",
    "    6. Select 'axial strain', select beam parts, unselect all other solid parts\n",
    "    4. Output 'Element results' and append all (axs)\n",
    "\n",
    "    The resulted txt file contains:\n",
    "    1. The init particle id (eid) with part id (pid)\n",
    "    2. For each timestep:\n",
    "        2.1 solid particle position (pid,x,y,z)\n",
    "        2.2 beam particle position (pid,x,y,z)\n",
    "    3. For each timestep, the solid particle strain (eps) (pid, eps)\n",
    "    4. And then for each timestep, the beam particle strain (axs) (pid, eps)\n",
    "    Note if element errosion is adopted, the num_particle per timestep may vary,\n",
    "    but eliminated particles are consistent between position and strain\n",
    "\n",
    "    Output: np arrays\n",
    "        tracjectory: (timesteps, num_particles, 3), \n",
    "        particle_types: (num_particles),  # if without errosion\n",
    "        strains: (timesteps, num_particles).       \n",
    "    '''\n",
    "\n",
    "    with open(file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    pos_lines_start, end_lines = [], []\n",
    "    solid_strain_lines_start, beam_strain_lines_start = [], []\n",
    "    for idx, line in enumerate(lines):\n",
    "        if line.startswith(\"*ELEMENT_SOLID\"):\n",
    "            type_line_start = idx\n",
    "        elif line.startswith(\"$Eid, X, Y, Z, Volume\"):\n",
    "            pos_lines_start.append(idx)\n",
    "        elif line.startswith(\"$RESULT OF Effective Plastic Strain (Unaveraged)\"):\n",
    "            solid_strain_lines_start.append(idx)\n",
    "        elif line.startswith(\"$RESULT OF Axial Strain (Unaveraged)\"):  \n",
    "            beam_strain_lines_start.append(idx)\n",
    "        elif line.startswith(\"*END\"):  # $NODAL_RESULTS,(1d) *INITIAL_VELOCITY_NODE(2d)\n",
    "            end_lines.append(idx)\n",
    "\n",
    "    type_line_end = end_lines[0]    # the first *END is for particle type\n",
    "    num_timesteps = len(pos_lines_start)\n",
    "    pos_lines_end = end_lines[1:num_timesteps+1]\n",
    "    solid_strain_lines_end = end_lines[num_timesteps+1:2*num_timesteps+1]\n",
    "    beam_strain_lines_end = end_lines[2*num_timesteps+1:]\n",
    "\n",
    "    # Extact particle types\n",
    "    particle_types = []\n",
    "    eids = []\n",
    "    for line in lines[type_line_start:type_line_end]:\n",
    "        num_str = re.findall(re_int_sci, line)  # Regular expression findign integers\n",
    "        if len(num_str) >= 4:\n",
    "            eid = int(num_str[0])\n",
    "            pid = int(num_str[1])\n",
    "            particle_type = PID_TO_TYPE[pid]\n",
    "            eids.append(eid)\n",
    "            particle_types.append((eid, particle_type))\n",
    "    particle_types = np.array(particle_types).astype(int)\n",
    "\n",
    "    # Extact particle positions \n",
    "    trajectory = []\n",
    "    for line_start, line_end in zip(pos_lines_start, pos_lines_end):\n",
    "        pos_lines = lines[line_start+1:line_end]   # lines that contains positions in one time step\n",
    "        pos_one_step = []\n",
    "        for line in pos_lines:\n",
    "            num_str = re.findall(re_int_sci, line)  # Regular expression findign scitific numbers\n",
    "            if len(num_str) >= 4:\n",
    "                pos = [float(x) for x in num_str[:4]] # [eid, x, y, z]\n",
    "                pos = tuple(pos)\n",
    "                pos_one_step.append(pos)\n",
    "        trajectory.append(pos_one_step) \n",
    "    trajectory = np.array(trajectory)\n",
    "\n",
    "    # Extract effective plastic strain for solids (eps)\n",
    "    solid_strains = []\n",
    "    for line_start, line_end in zip(solid_strain_lines_start, solid_strain_lines_end):\n",
    "        strain_lines = lines[line_start+1:line_end]   # lines that contains positions in one time step\n",
    "        strains_one_step = []\n",
    "        for line in strain_lines:\n",
    "            num_str = re.findall(re_int_sci, line)  # Regular expression findign scitific numbers\n",
    "            if len(num_str) == 2:\n",
    "                num = [float(x) for x in num_str]\n",
    "                strains_one_step.append(tuple(num))\n",
    "        solid_strains.append(strains_one_step)\n",
    "    solid_strains = np.array(solid_strains).astype(float)\n",
    "\n",
    "    # Extract axial strain for beams (axs)\n",
    "    beam_strains = []\n",
    "    for line_start, line_end in zip(beam_strain_lines_start, beam_strain_lines_end):\n",
    "        strain_lines = lines[line_start+1:line_end]   # lines that contains positions in one time step\n",
    "        strains_one_step = []\n",
    "        for line in strain_lines:\n",
    "            num_str = re.findall(re_int_sci, line)  # Regular expression findign scitific numbers\n",
    "            if len(num_str) == 2:\n",
    "                num = [float(x) for x in num_str]\n",
    "                strains_one_step.append(tuple(num))\n",
    "        beam_strains.append(strains_one_step)\n",
    "    beam_strains = np.array(beam_strains).astype(float)\n",
    "\n",
    "    # Concatenate solid and beam \n",
    "    strains = np.concatenate((solid_strains, beam_strains), axis=1)\n",
    "\n",
    "    # Sort based on eid\n",
    "    idx = particle_types[:, 0].argsort()\n",
    "    particle_types = particle_types[idx, 1]\n",
    "\n",
    "    idx = strains[0, :, 0].argsort()\n",
    "    strains = strains[:, idx, 1]\n",
    "\n",
    "    idx = trajectory[0, :, 0].argsort()\n",
    "    trajectory = trajectory[:, idx, 1:]\n",
    "\n",
    "    print('trajectory: ', trajectory.shape)\n",
    "    print('particle_types: ', particle_types.shape)\n",
    "    print('strains :', strains.shape)\n",
    "\n",
    "    return trajectory, particle_types, strains\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "244aa8fe-0913-4d4b-92f4-c74698cbf200",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/1 Reading /home/jovyan/work/data_temp/segment_beam/DYNA/seg_beam_100steps...\n",
      "trajectory:  (101, 49814, 3)\n",
      "particle_types:  (49814,)\n",
      "strains : (101, 49814)\n",
      "Dim: 3\n",
      "Position min:[-161.34921  -237.68245   -68.810745], max:[ 161.47427  650.03168 1617.6865 ]\n",
      "Strain min:-0.003369695, max:1.9999939\n",
      "Shape, pos: (34, 49814, 3), types: (49814,), strain: (34, 49814)\n",
      "Unique particle types: [0 1 2 3 4]\n",
      "to train\n",
      "to valid\n",
      "to test\n",
      "1 trajectories saved to train.npz.\n",
      "1 trajectories saved to valid.npz.\n",
      "1  trajectories saved to test.npz.\n",
      "{'bounds': [[-170, 170], [-250, 660], [-80, 1630]], 'sequence_length': 34, 'default_connectivity_radius': 15, 'dim': 3, 'dt': 0.03, 'vel_mean': [-0.001834683072605822, 0.017270407932242788, -0.11164911523248897], 'vel_std': [0.04751214060138093, 1.0044909292099198, 0.20779822103955548], 'acc_mean': [-0.0005519265941803202, 0.06471453574952156, -0.0004543210862477105], 'acc_std': [0.06523576891911972, 0.3524579119577412, 0.09076977260142277], 'file_train': ['/home/jovyan/work/data_temp/segment_beam/DYNA/seg_beam_100steps'], 'file_valid': ['/home/jovyan/work/data_temp/segment_beam/DYNA/seg_beam_100steps'], 'file_test': ['/home/jovyan/work/data_temp/segment_beam/DYNA/seg_beam_100steps']}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import pathlib\n",
    "       \n",
    "dataset = 'segment_beam'\n",
    "in_dir = f'/home/jovyan/work/data_temp/{dataset}/DYNA/'\n",
    "out_dir = f'/home/jovyan/work/data_temp/{dataset}/'\n",
    "pathlib.Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Grab all simulation cases from corresponding data folder\n",
    "simulations = glob.glob(in_dir +'*')\n",
    "random.shuffle(simulations)\n",
    "\n",
    "## Larger step size leads to shorter trajectory and hence better rollout performance\n",
    "## But lower precision of the simulation\n",
    "## Current simulation are of absolute time 1000 ms\n",
    "## Step size=1 means 100 steps, each of which 10 ms\n",
    "STEP_SIZE = 3\n",
    "\n",
    "## Initialisation placeholders for data\n",
    "n_trajectory = len(simulations)\n",
    "ds_train, ds_valid, ds_test = {}, {}, {}\n",
    "vels = np.array([]).reshape(0, 3)\n",
    "accs = np.array([]).reshape(0, 3)\n",
    "strain_stats = np.array([])\n",
    "file_train, file_valid, file_test = [], [], []\n",
    "\n",
    "## Main loop for data extraction\n",
    "for idx, simulation in enumerate(simulations):\n",
    "    print(f\"{idx}/{n_trajectory} Reading {simulation}...\")\n",
    "    positions, particle_types, strains = parse_segment_simulation(simulation)\n",
    "    dim = positions.shape[-1]\n",
    "    \n",
    "    positions = positions[::STEP_SIZE, :, :]\n",
    "    \n",
    "    strains = strains[::STEP_SIZE, :]\n",
    "       \n",
    "    # print for debug\n",
    "    print(f\"Dim: {dim}\")\n",
    "    print(f\"Position min:{positions.min(axis=(0,1))}, max:{positions.max(axis=(0,1))}\")\n",
    "    print(f\"Strain min:{strains.min(axis=(0,1))}, max:{strains.max(axis=(0,1))}\")\n",
    "    print(f\"Shape, pos: {positions.shape}, types: {particle_types.shape}, strain: {strains.shape}\")\n",
    "    print(f\"Unique particle types: {np.unique(particle_types)}\")\n",
    "    \n",
    "    # Data splits: train(80%), valid(10%), test(10%)\n",
    "    key = f'trajectory_{idx}' \n",
    "    if True:\n",
    "        print('to train')\n",
    "        ds_train[key] = [positions, particle_types, strains]\n",
    "        file_train.append(simulation)\n",
    "    if True:\n",
    "        print('to valid')\n",
    "        ds_valid[key] = [positions, particle_types, strains]\n",
    "        file_valid.append(simulation)\n",
    "    if True:\n",
    "        print('to test')\n",
    "        ds_test[key] = [positions, particle_types, strains]\n",
    "        file_test.append(simulation)\n",
    "        \n",
    "    # Extract Vel and Acc statistics\n",
    "    # positions of shape [timestep, particles, dimensions]\n",
    "    vel_trajectory = positions[1:,:,:] - positions[:-1,:,:]\n",
    "    acc_trajectory = vel_trajectory[1:,:,:]- vel_trajectory[:-1,:,:]\n",
    "    \n",
    "    vels = np.concatenate((vels, vel_trajectory.reshape(-1, dim)), axis=0)\n",
    "    accs = np.concatenate((accs, acc_trajectory.reshape(-1, dim)), axis=0)\n",
    "\n",
    "# Extract vel, acc statistics for normalisation\n",
    "vel_mean, vel_std = list(vels.mean(axis=0)), list(vels.std(axis=0))\n",
    "acc_mean, acc_std = list(accs.mean(axis=0)), list(accs.std(axis=0))\n",
    "\n",
    "# Save datasets in numpy format\n",
    "np.savez(out_dir + 'train.npz', **ds_train)\n",
    "np.savez(out_dir + 'valid.npz', **ds_valid)\n",
    "np.savez(out_dir + 'test.npz', **ds_test)\n",
    "\n",
    "print(f\"{len(ds_train)} trajectories saved to train.npz.\")\n",
    "print(f\"{len(ds_valid)} trajectories saved to valid.npz.\")\n",
    "print(f\"{len(ds_test)}  trajectories saved to test.npz.\")\n",
    "\n",
    "# Save meta data\n",
    "in_file = '/home/jovyan/share/gns_data/Concrete2D-C/metadata.json'\n",
    "out_file = out_dir + 'metadata.json'\n",
    "\n",
    "with open(in_file, 'r') as f:\n",
    "    meta_data = json.load(f)\n",
    "\n",
    "# In GNN, the suggested connection radius is 4.5r, or 5.625 mm (aounrd 20 neighbors)\n",
    "# If R is 5 mm before normalization, \n",
    "meta_data['dim'] = 3\n",
    "meta_data['default_connectivity_radius'] = 15 \n",
    "meta_data['sequence_length'] = positions.shape[0]\n",
    "meta_data['vel_mean'] = vel_mean\n",
    "meta_data['vel_std'] = vel_std\n",
    "meta_data['acc_mean'] = acc_mean\n",
    "meta_data['acc_std'] = acc_std\n",
    "\n",
    "meta_data['dt'] = 0.01 * STEP_SIZE\n",
    "meta_data['bounds'] = [[-170, 170], [-250, 660], [-80, 1630]]\n",
    "meta_data['file_train'] = file_train\n",
    "meta_data['file_valid'] = file_valid\n",
    "meta_data['file_test'] = file_test\n",
    "print(meta_data)\n",
    "\n",
    "with open(out_file, 'w') as f:\n",
    "    json.dump(meta_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966eb557-29f5-4f3b-86f4-fd42353df575",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Modify metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f182a3-c205-46ce-9c02-e13ba4635842",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = '/home/jovyan/share/gns_data/Fragment/metadata.json'\n",
    "out_file = f'/home/jovyan/work/data_temp/fragment/Fragment/metadata.json'\n",
    "\n",
    "with open(in_file, 'r') as f:\n",
    "    meta_data = json.load(f)\n",
    "\n",
    "meta_data['dim'] = 3\n",
    "meta_data['bounds'] = [[-500, 500], [-1000, 1000], [0, 255]]\n",
    "\n",
    "print(meta_data)\n",
    "\n",
    "with open(out_file, 'w') as f:\n",
    "    json.dump(meta_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6030fd9-c4e2-4e22-93c7-3c3e8671a802",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Test regular expression for number extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d25e860-bb0a-4645-9e5a-2b2a08a8cc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "strs = ['20742   1.4952594e+03   -1.0499660e+02   1.6313647e-02   9.9995575e+02',\n",
    "        '    32365   1.4051317e+00',\n",
    "        '   10826       1   15757   15758   15784   15783   11311   11312   11338   11337',\n",
    "        '$Total Solid element Volume =    7.5878880e+07'\n",
    "       ]\n",
    "\n",
    "pattern = r'[+-]?\\d+\\.\\d+e[+-]?[\\d]+'\n",
    "for str in strs:\n",
    "    print(re.findall(pattern, str))\n",
    "    \n",
    "pattern = r'[-\\d\\.]+e?[-+\\d]*'\n",
    "for str in strs:\n",
    "    print(re.findall(pattern, str))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92542ac9-5dfe-4de9-87a2-4d715b9f7832",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot segment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c2388-3f91-4d16-9a05-b1d0ca4eb489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from absl import app\n",
    "from absl import flags\n",
    "\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def colormap(strains):\n",
    "    \"\"\"\n",
    "    Create a colormap for each timestep based on strain\n",
    "    \"\"\"\n",
    "    color_map = []\n",
    "    for t in range(101):\n",
    "        normalized_strain = mcolors.Normalize(\n",
    "            vmin=0, \n",
    "            vmax=2\n",
    "        )\n",
    "        colormap = plt.get_cmap('jet')\n",
    "        color_map.append(colormap(normalized_strain(strains[t])))\n",
    "    return color_map\n",
    "\n",
    "# Init figures\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Get boundary of simulation\n",
    "xmin, ymin, zmin = trajectory.min(axis=(0,1))\n",
    "xmax, ymax, zmax = trajectory.max(axis=(0,1))\n",
    "ax.set_box_aspect([xmax-xmin, ymax-ymin, zmax-zmin])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05)\n",
    "# Fig creating function for 3d\n",
    "def animate(i):\n",
    "    print(f\"Render step {i}/101...\")\n",
    "\n",
    "    fig.clear()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.set_box_aspect([xmax-xmin, ymax-ymin, zmax-zmin])\n",
    "    color_map = colormap(strains)\n",
    "    \n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    ax.set_xlim([float(xmin), float(xmax)])\n",
    "    ax.set_ylim([float(ymin), float(ymax)])\n",
    "    ax.set_zlim([float(zmin), float(zmax)])\n",
    "    ax.scatter(trajectory[i, :, 0],\n",
    "               trajectory[i, :, 1],\n",
    "               trajectory[i, :, 2], \n",
    "               s=1, \n",
    "               color=color_map[i]\n",
    "              )\n",
    "    # rotate viewpoints angle little by little for each timestep\n",
    "    ax.view_init(elev=20, azim=0, roll=0, vertical_axis='z')\n",
    "    ax.grid(True, which='both')\n",
    "    ax.set_title('LS-DYNA')\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05)\n",
    "\n",
    "# Creat animation\n",
    "ani = animation.FuncAnimation(\n",
    "    fig, animate, frames=np.arange(0, 101, 10), interval=10)\n",
    "\n",
    "ani.save(f'seg_beam.gif', dpi=100, fps=10, writer='Pillow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83dc3a23-917e-4e19-adc8-f027c83e7160",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-161.35165 161.47925\n",
      "-237.68259 650.07532\n",
      "-68.812531 1617.7135\n"
     ]
    }
   ],
   "source": [
    "print(xmin, xmax)\n",
    "print(ymin, ymax)\n",
    "print(zmin, zmax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gns",
   "language": "python",
   "name": "gns"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
